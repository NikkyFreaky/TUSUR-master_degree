import time
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor
from pathlib import Path

import cv2 as cv
import numpy as np
import pandas as pd

# ======================= –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ==========================
RGB_RANGE = ((214, 117, 13), (255, 197, 93))
MIN_AREA = 500
KERNEL_SIZE = 9
NUM_RUNS = 5
PROCESS_COUNTS = [1, 2, 4, 6, 8, 10]

# ======================= –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ==========================


def get_video_prefix(filename):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ (–¥–æ –ø–µ—Ä–≤–æ–≥–æ —á–∏—Å–ª–∞ —Å 'p')"""
    parts = filename.split("_")
    for i, part in enumerate(parts):
        if part.endswith("p") and any(c.isdigit() for c in part):
            return "_".join(parts[:i])
    return filename.split("_")[0]


def scan_input_videos(input_dir="input"):
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç –ø–∞–ø–∫—É input –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º"""
    input_path = Path(input_dir)
    if not input_path.exists():
        input_path.mkdir()
        print(f"–°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ {input_dir}. –ü–æ–º–µ—Å—Ç–∏—Ç–µ —Ç—É–¥–∞ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã.")
        return {}

    video_groups = defaultdict(list)
    video_extensions = {".mp4", ".avi", ".mov", ".mkv"}

    for video_file in input_path.iterdir():
        if video_file.suffix.lower() in video_extensions:
            prefix = get_video_prefix(video_file.stem)

            # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ
            cap = cv.VideoCapture(str(video_file))
            fps = cap.get(cv.CAP_PROP_FPS)
            frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))
            duration = int(frame_count / fps) if fps > 0 else 0
            cap.release()

            video_groups[prefix].append(
                {"path": str(video_file), "duration": duration, "name": video_file.name}
            )

    return video_groups


def process_range(
    input_path,
    output_path,
    lower_rgb,
    upper_rgb,
    min_area,
    kernel_size,
    start_frame,
    end_frame,
    part_index,
):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞—Å—Ç–∏ –∫–∞–¥—Ä–æ–≤ –≤–∏–¥–µ–æ ‚Äî –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
    cap = cv.VideoCapture(input_path)
    fps = cap.get(cv.CAP_PROP_FPS)
    w = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))
    cap.set(cv.CAP_PROP_POS_FRAMES, start_frame)

    out = cv.VideoWriter(output_path, cv.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

    # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ —è–¥—Ä–æ –¥–ª—è —Ä–∞–∑–º—ã—Ç–∏—è
    kernel = np.ones((kernel_size, kernel_size), np.float32) / (kernel_size**2)

    # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω–∞—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
    morph_kernel = np.ones((3, 3), np.uint8)
    dilate_kernel = np.ones((3, 3), np.uint8)

    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    COLORS = [
        (0, 255, 0),
        (255, 0, 0),
        (0, 0, 255),
        (255, 255, 0),
        (255, 0, 255),
        (0, 255, 255),
        (255, 128, 0),
        (128, 0, 255),
        (0, 128, 255),
        (128, 255, 0),
    ]
    color = COLORS[part_index % len(COLORS)]
    thickness = 2 + part_index % 3

    # –ü—Ä–µ–¥–≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã numpy –¥–ª—è RGB –¥–∏–∞–ø–∞–∑–æ–Ω–∞
    lower_rgb_array = np.array(lower_rgb, dtype=np.uint8)
    upper_rgb_array = np.array(upper_rgb, dtype=np.uint8)

    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    frames_to_process = end_frame - start_frame

    for _ in range(frames_to_process):
        ret, frame = cap.read()
        if not ret:
            break

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è BGR -> RGB
        rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)

        # –ë–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞ –ø–æ —Ü–≤–µ—Ç—É
        mask = cv.inRange(rgb, lower_rgb_array, upper_rgb_array)
        mask = cv.morphologyEx(mask, cv.MORPH_OPEN, morph_kernel)

        n_labels, labels, stats, _ = cv.connectedComponentsWithStats(
            mask, connectivity=8
        )

        # –°–æ–∑–¥–∞—ë–º –º–∞—Å–∫—É –æ–±–ª–∞—Å—Ç–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑–∫–æ—Å—Ç–∏
        region_mask = np.zeros((h, w), dtype=np.uint8)

        valid_regions = []
        for i in range(1, n_labels):
            area = stats[i, cv.CC_STAT_AREA]
            if area >= min_area:
                x = stats[i, cv.CC_STAT_LEFT]
                y = stats[i, cv.CC_STAT_TOP]
                w_box = stats[i, cv.CC_STAT_WIDTH]
                h_box = stats[i, cv.CC_STAT_HEIGHT]

                cv.rectangle(region_mask, (x, y), (x + w_box, y + h_box), 255, -1)
                valid_regions.append((x, y, w_box, h_box))

        # –†–∞—Å—à–∏—Ä—è–µ–º –º–∞—Å–∫—É –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—Ä–µ–æ–ª–∞
        region_mask = cv.dilate(region_mask, dilate_kernel, iterations=1)

        # –†–∞–∑–º—ã—Ç–∏–µ (–ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∫–∞–¥—Ä—É)
        blurred = cv.filter2D(frame, -1, kernel)

        # –ö–æ–ø–∏—Ä—É–µ–º —Ä–∞–∑–º—ã—Ç—ã–π –∫–∞–¥—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤—É
        result = blurred.copy()

        # –†–∏—Å—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –Ω–∞ –∫–æ–ø–∏–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        annotated = frame.copy()
        for x, y, w_box, h_box in valid_regions:
            cv.rectangle(annotated, (x, y), (x + w_box, y + h_box), color, thickness)
            cv.putText(
                annotated,
                f"P{part_index}",
                (x + 5, y + 20),
                cv.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2,
                cv.LINE_AA,
            )

        # –í—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∑–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏ –ø–æ–≤–µ—Ä—Ö —Ä–∞–∑–º—ã—Ç–æ–≥–æ —Ñ–æ–Ω–∞
        cv.copyTo(annotated, region_mask, result)

        out.write(result)

    cap.release()
    out.release()


def concat_videos(temp_files, output_path, fps):
    """–°–∫–ª–µ–π–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ"""
    first = cv.VideoCapture(temp_files[0])
    w = int(first.get(cv.CAP_PROP_FRAME_WIDTH))
    h = int(first.get(cv.CAP_PROP_FRAME_HEIGHT))
    first.release()

    out = cv.VideoWriter(output_path, cv.VideoWriter_fourcc(*"mp4v"), fps, (w, h))

    for part in temp_files:
        cap = cv.VideoCapture(part)
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            out.write(frame)
        cap.release()

    out.release()


def process_video_parallel(
    input_path, output_path, lower_rgb, upper_rgb, min_area, kernel_size, num_processes
):
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Ä–∞–∑–±–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –ø–æ –∫–∞–¥—Ä–∞–º –º–µ–∂–¥—É –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏"""
    cap = cv.VideoCapture(input_path)
    frame_count = int(cap.get(cv.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv.CAP_PROP_FPS)
    cap.release()

    frames_per_part = frame_count // num_processes
    temp_files = []

    with ProcessPoolExecutor(max_workers=num_processes) as executor:
        futures = []
        for i in range(num_processes):
            start = i * frames_per_part
            end = frame_count if i == num_processes - 1 else (i + 1) * frames_per_part
            temp_file = f"output/temp_part_{i}.mp4"
            temp_files.append(temp_file)
            futures.append(
                executor.submit(
                    process_range,
                    input_path,
                    temp_file,
                    lower_rgb,
                    upper_rgb,
                    min_area,
                    kernel_size,
                    start,
                    end,
                    i,
                )
            )

        for f in futures:
            f.result()

    concat_videos(temp_files, output_path, fps)

    for f in temp_files:
        Path(f).unlink(missing_ok=True)


# ======================= Benchmark ==========================


def run_once(video_path, num_processes, run_index, video_prefix):
    """–ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞"""
    video_name = Path(video_path).stem
    out_path = f"output/{video_prefix}_p{num_processes}_r{run_index}_{video_name}.mp4"

    t0 = time.perf_counter()
    process_video_parallel(
        input_path=video_path,
        output_path=out_path,
        lower_rgb=RGB_RANGE[0],
        upper_rgb=RGB_RANGE[1],
        min_area=MIN_AREA,
        kernel_size=KERNEL_SIZE,
        num_processes=num_processes,
    )
    elapsed = time.perf_counter() - t0
    return elapsed, out_path


def benchmark():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    import matplotlib.pyplot as plt
    import seaborn as sns

    # === –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ ===
    print("–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ input...")
    video_groups = scan_input_videos()

    if not video_groups:
        print("‚ö†Ô∏è  –í –ø–∞–ø–∫–µ input –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤!")
        return

    print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(video_groups)} –≥—Ä—É–ø–ø—ã –≤–∏–¥–µ–æ:")
    for prefix, videos in video_groups.items():
        print(f"  - {prefix}: {len(videos)} –≤–∏–¥–µ–æ")
        for v in videos:
            print(f"    ‚Ä¢ {v['name']} ({v['duration']}s)")

    # === –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
    output_dir = Path("output")
    if output_dir.exists():
        for file in output_dir.glob("*.mp4"):
            try:
                file.unlink()
            except Exception as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {file}: {e}")
    else:
        output_dir.mkdir()

    plots_dir = Path("plots")
    if plots_dir.exists():
        for file in plots_dir.glob("*.png"):
            try:
                file.unlink()
            except Exception as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {file}: {e}")
    else:
        plots_dir.mkdir()

    results_csv = Path("results.csv")
    if results_csv.exists():
        results_csv.unlink()

    print("\n–ü–∞–ø–∫–∏ output –∏ plots –æ—á–∏—â–µ–Ω—ã, –Ω–∞—á–∏–Ω–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫...\n")

    # === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±–µ–Ω—á–º–∞—Ä–∫–∞ ===
    all_results = []

    for prefix, videos in video_groups.items():
        print(f"\n{'=' * 60}")
        print(f"–ì–†–£–ü–ü–ê: {prefix}")
        print("=" * 60)

        for workers in PROCESS_COUNTS:
            print(f"\n=== –¢–µ—Å—Ç–∏—Ä—É–µ–º {workers} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ ===")
            best_times = {}

            for run in range(NUM_RUNS):
                print(f"\n--- –ó–∞–ø—É—Å–∫ {run + 1}/{NUM_RUNS} ---")

                for video_info in videos:
                    video_path = video_info["path"]
                    duration = video_info["duration"]
                    video_name = video_info["name"]

                    elapsed, out_path = run_once(video_path, workers, run, prefix)

                    all_results.append(
                        {
                            "group": prefix,
                            "video": video_name,
                            "duration": duration,
                            "processes": workers,
                            "run": run + 1,
                            "elapsed_time": elapsed,
                        }
                    )

                    print(f"{video_name}: {elapsed:.2f} —Å")

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∏–¥–µ–æ
                    key = (video_name, workers)
                    if key not in best_times or elapsed < best_times[key][0]:
                        if key in best_times and Path(best_times[key][1]).exists():
                            Path(best_times[key][1]).unlink()
                        best_times[key] = (elapsed, out_path)
                    else:
                        if Path(out_path).exists():
                            Path(out_path).unlink()

            # –í—ã–≤–æ–¥ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for video_info in videos:
                video_name = video_info["name"]
                key = (video_name, workers)
                if key in best_times:
                    print(
                        f"–õ—É—á—à–∏–π –¥–ª—è {video_name} ({workers} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤): {best_times[key][0]:.2f} —Å"
                    )

    # === –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV ===
    df = pd.DataFrame(all_results)
    df.to_csv(results_csv, index=False)
    print(f"\n‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_csv}")

    # === –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã ===
    sns.set_theme(style="whitegrid")

    for prefix in video_groups.keys():
        subset = df[df["group"] == prefix]

        if subset.empty:
            continue

        # 1. –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        summary = subset.groupby("processes", as_index=False)["elapsed_time"].mean()

        plt.figure(figsize=(10, 6))
        sns.lineplot(
            data=summary, x="processes", y="elapsed_time", marker="o", linewidth=2.5
        )
        plt.title(f"Average Processing Time ‚Äî {prefix}", fontsize=14, fontweight="bold")
        plt.xlabel("Number of Processes", fontsize=12)
        plt.ylabel("Average Time (seconds)", fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        fname_avg = plots_dir / f"{prefix}_avg_time.png"
        plt.savefig(fname_avg, dpi=200)
        plt.close()

        # 2. Boxplot —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        plt.figure(figsize=(10, 6))
        sns.boxplot(data=subset, x="processes", y="elapsed_time", palette="Set2")
        plt.title(f"Time Distribution ‚Äî {prefix}", fontsize=14, fontweight="bold")
        plt.xlabel("Number of Processes", fontsize=12)
        plt.ylabel("Execution Time (seconds)", fontsize=12)
        plt.grid(True, axis="y", alpha=0.3)
        plt.tight_layout()

        fname_box = plots_dir / f"{prefix}_boxplot.png"
        plt.savefig(fname_box, dpi=200)
        plt.close()

        print(f"üìä –ì—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã '{prefix}': {fname_avg.name}, {fname_box.name}")

    print(f"\n‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø–∞–ø–∫–µ 'plots/'")
    print(f"üìÅ –õ—É—á—à–∏–µ –≤–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ 'output/'")


if __name__ == "__main__":
    benchmark()
